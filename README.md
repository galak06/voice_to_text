# üé§ Hebrew Voice to Text - Final Version

**Clean, streamlined Hebrew audio transcription with speaker separation and Word document output.**

## ‚ú® Features

- üó£Ô∏è **Hebrew transcription** using OpenAI Whisper
- üë• **Speaker separation** by paragraphs (alternating speakers)
- üìÑ **Word document output** (.docx) with professional formatting
- üéØ **Multiple model sizes** (tiny, base, small, medium, large)
- üìä **Progress bars** for model loading and transcription
- üé® **Rich console output** with detailed information
- üîß **Easy to use** with simple command line interface

## üìÅ Project Structure

```
voice_to_text/
‚îú‚îÄ‚îÄ transcribe_hebrew.py          # Main transcription script
‚îú‚îÄ‚îÄ run_hebrew.sh                 # Runner script
‚îú‚îÄ‚îÄ create_test_audio.py          # Test audio generator
‚îú‚îÄ‚îÄ setup.py                      # Package setup
‚îú‚îÄ‚îÄ install.sh                    # Environment installer
‚îú‚îÄ‚îÄ environment.yml               # Conda environment
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ .env                          # Hugging Face token (create this)
‚îú‚îÄ‚îÄ voice/                        # Input audio files
‚îÇ   ‚îú‚îÄ‚îÄ rachel_1.wav             # Original Hebrew audio
‚îÇ   ‚îî‚îÄ‚îÄ test_conversation.wav    # Test audio (30s, 2 voices)
‚îî‚îÄ‚îÄ output/                       # Generated files (with timestamps)
    ‚îú‚îÄ‚îÄ rachel_1_hebrew_speakers_tiny_20250730_194340.docx
    ‚îî‚îÄ‚îÄ rachel_1_hebrew_speakers_large_20250730_195000.docx
```

## üöÄ Quick Start

### 1. Setup Environment
```bash
# Create conda environment
conda env create -f environment.yml

# Activate environment
conda activate voice-to-text
```

### 2. Configure Hugging Face Token
```bash
# Create .env file with your token
echo "HUGGINGFACE_TOKEN=your_token_here" > .env
```

### 3. Run Transcription
```bash
# Fastest (for testing)
./run_hebrew.sh --model tiny

# Good balance (production)
./run_hebrew.sh --model base

# Best quality (slower)
./run_hebrew.sh --model medium

# With GPU acceleration (if available)
./run_hebrew.sh --model tiny --device cuda

# Parallel processing for multiple files (minimum 2 workers)
./run_hebrew.sh --model tiny --workers 4

# Performance optimized (default)
./run_hebrew.sh --model tiny --process-folder

# Minimal memory usage
./run_hebrew.sh --model tiny --no-cache --no-optimize

# Raw text without speaker separation
./run_hebrew.sh --model tiny --no-text-improvements
```

## üìã Usage Examples

### Basic Usage
```bash
# Process all audio files in voice/ folder (with timestamps)
./run_hebrew.sh

# Use specific model
./run_hebrew.sh --model medium

# Process specific file (with timestamp)
./run_hebrew.sh voice/test_conversation.wav

# Process specific file with custom output
./run_hebrew.sh voice/test_conversation.wav output/test_output.docx
```

### Model Options
- **tiny**: ~39MB, fastest, basic quality
- **base**: ~74MB, fast, good quality  
- **small**: ~244MB, balanced
- **medium**: ~769MB, good quality (default)
- **large**: ~1550MB, best quality, slowest

### Speed Optimizations
- **GPU acceleration**: 10x faster with CUDA
- **FP16 optimization**: 2x faster on GPU
- **Model caching**: Faster reloads (~/.cache/whisper)
- **Performance optimizations**: PyTorch optimizations, thread tuning
- **Parallel processing**: Minimum 2 workers (default: 2, recommended: 4)
- **Fast settings**: Optimized for tiny model
- **Memory optimization**: Disable cache/optimizations with `--no-cache --no-optimize`
- **Text improvements**: Speaker separation and paragraph formatting (disable with `--no-text-improvements`)

## üéØ Output Format

### Word Document Structure
```
Hebrew Voice Transcription
Audio File: rachel_1.wav
Model: medium | Language: Hebrew | Speakers: 2
____________________________________________________________

Speaker 1
Sentence 1: [Hebrew text in RTL]

Speaker 2
Sentence 2: [Hebrew text in RTL]

Speaker 1
Sentence 3: [Hebrew text in RTL]

Speaker 2
Sentence 4: [Hebrew text in RTL]
...

____________________________________________________________
Summary: X sentences from Speaker 1, Y sentences from Speaker 2
```

### Speaker Separation Logic
- Text is split into individual sentences
- Each sentence alternates between speakers: Speaker 1 ‚Üí Speaker 2 ‚Üí Speaker 1 ‚Üí etc.
- Speakers alternate in chronological order
- Output maintains time order: Speaker 1 sentence, then Speaker 2 sentence, then Speaker 1 sentence, etc.

## üîß Technical Details

### Dependencies
- **Python 3.10+**
- **OpenAI Whisper** (transcription)
- **python-docx** (Word document generation)
- **rich** (console output)
- **python-dotenv** (environment variables)
- **scipy** (test audio generation)

### Configuration
- **Language**: Hebrew (he)
- **Temperature**: 0.0 (most accurate)
- **Best of**: 5 candidates (1 for tiny model)
- **Beam size**: 5 (1 for tiny model)
- **Word timestamps**: Disabled
- **Initial prompt**: "This is a Hebrew conversation between two speakers."
- **FP16**: Enabled on GPU for 2x speed
- **Device**: Auto-detect GPU/CPU

## üß™ Testing

### Create Test Audio
```bash
python create_test_audio.py
```
Creates `voice/test_conversation.wav` (30 seconds, 2 alternating voices)

### Test Transcription
```bash
# Quick test with tiny model
./run_hebrew.sh --model tiny

# Test with GPU (if available)
./run_hebrew.sh --model tiny --device cuda

# Test parallel processing
./run_hebrew.sh --model tiny --workers 2
```

## üìä Quality Metrics

The system provides quality scoring based on:
- Text length
- Hebrew character density
- Punctuation and structure
- Overall coherence

Quality levels:
- **8.0-10.0**: üéØ Excellent quality
- **6.0-7.9**: ‚úÖ Good quality  
- **0.0-5.9**: ‚ö†Ô∏è Quality could be improved

## üé® Features

### Progress Tracking
- Model loading progress bar
- Transcription progress with time estimation
- Rich console tables and status indicators

### Professional Output
- Word document with proper Hebrew RTL formatting
- Speaker sections with color-coded paragraph numbers
- Document metadata and summary
- Clean, readable formatting

### Error Handling
- Graceful handling of missing files
- Clear error messages
- Environment validation
- Model access verification

## üîÑ Workflow

1. **Place audio files** in `voice/` folder
2. **Run transcription** with desired model size
3. **Get Word document** in `output/` folder
4. **Review speaker separation** and formatting
5. **Adjust model size** if needed for quality/speed

## üìù Notes

- **GPU acceleration** available if CUDA is installed
- **Hugging Face token** required for some advanced features
- **Hebrew RTL** text properly formatted in Word documents
- **Speaker separation** is heuristic-based (not true diarization)
- **File formats** supported: .wav, .mp3, .m4a, .flac, .aac

## üéØ Success Metrics

‚úÖ **Clean, streamlined codebase**  
‚úÖ **Professional Word document output**  
‚úÖ **Speaker separation by paragraphs**  
‚úÖ **Multiple model size options**  
‚úÖ **Speed optimizations (GPU, FP16, parallel)**  
‚úÖ **Progress tracking and rich UI**  
‚úÖ **Test audio generation**  
‚úÖ **Comprehensive documentation**  

---

**Final Version**: Clean, efficient, and ready for production use! üöÄ 